import os
import pandas as pd
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder


def load_data(file_path):
    xl = pd.ExcelFile(file_path)

    for i in range(10):
        temp_df = xl.parse(sheet_name='æ•°æ®é›†', header=i)
        if 'b_aab022' in temp_df.columns:
            header_row = i
            break
    else:
        raise ValueError("Error")

    data = xl.parse(sheet_name='æ•°æ®é›†', header=header_row)
    print(data.columns.tolist())

    return data


def load_data_pre(file_path):
    xl = pd.ExcelFile(file_path)

    for i in range(10):
        temp_df = xl.parse(sheet_name='é¢„æµ‹é›†', header=i)
        if 'c_aac181' in temp_df.columns:
            header_row = i
            break
    else:
        raise ValueError("Error")

    data = xl.parse(sheet_name='é¢„æµ‹é›†', header=header_row)
    print(data.columns.tolist())

    return data


def fill_multiple_categorical_columns(df, columns_to_fill):
    df = df.copy()
    for col in columns_to_fill:
        if col not in df.columns:
            continue
        print(f"ğŸ”„ æ­£åœ¨å¡«è¡¥ï¼š{col}...")
        not_null_df = df[df[col].notnull()]
        null_df = df[df[col].isnull()]
        if null_df.empty:
            continue

        # ç¼–ç å™¨åˆå§‹åŒ–
        label_encoders = {}

        X_train = not_null_df.drop(columns=columns_to_fill)
        y_train = not_null_df[col].astype(str)

        X_test = null_df.drop(columns=columns_to_fill)

        # å¯¹æ‰€æœ‰ç±»åˆ«å‹å˜é‡ç¼–ç 
        for column in X_train.select_dtypes(include='category').columns:
            le = LabelEncoder()
            all_vals = pd.concat([X_train[column], X_test[column]], axis=0).astype(str)
            le.fit(all_vals)
            X_train[column] = le.transform(X_train[column].astype(str))
            X_test[column] = le.transform(X_test[column].astype(str))
            label_encoders[column] = le

        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(X_train.select_dtypes(include=[np.number]), y_train)
        y_pred = rf.predict(X_test.select_dtypes(include=[np.number]))

        df.loc[df[col].isnull(), col] = y_pred
        print(f"âœ… å¡«è¡¥å®Œæˆï¼š{col}ï¼Œå¡«è¡¥æ•°é‡ {len(y_pred)}")

    return df

def advanced_missing_value_processing(df):
    missing_analysis = df.isna().agg(['sum', 'mean']).T
    missing_analysis.columns = ['ç¼ºå¤±æ•°é‡', 'ç¼ºå¤±æ¯”ä¾‹']
    missing_analysis = missing_analysis.sort_values(by='ç¼ºå¤±æ¯”ä¾‹', ascending=False)
    print("ç¼ºå¤±å€¼åˆ†ææŠ¥å‘Šï¼š\n", missing_analysis.head(10))

    # åˆ é™¤é«˜ç¼ºå¤±ç‡ç‰¹å¾ï¼ˆé˜ˆå€¼è®¾ä¸º70%ï¼‰
    high_missing_cols = missing_analysis[missing_analysis['ç¼ºå¤±æ¯”ä¾‹'] > 0.7].index.tolist()
    if high_missing_cols:
        print(f"ğŸš® åˆ é™¤é«˜ç¼ºå¤±ç‡ç‰¹å¾ï¼š{high_missing_cols}")
        df = df.drop(columns=high_missing_cols)

    # ğŸŒŸ æ¨¡å‹å¡«è¡¥éƒ¨åˆ†ç¼ºå¤±çš„ç±»åˆ«å˜é‡
    df = fill_multiple_categorical_columns(df, ['profession', 'c_aac182', 'c_aac183', 'c_aac009', 'c_aac011'])

    # âœ… æ¯•ä¸šå¹´ä»½æ¨ç®—ï¼ˆåº”æ”¾åœ¨ç›¸å…³å­—æ®µå¡«è¡¥åï¼‰
    if 'c_aac180' in df.columns and 'birthday' in df.columns:
        def infer_grad_year(row):
            if pd.notnull(row.get('graduate_year')):
                return row['graduate_year']
            school = str(row.get('c_aac180', ''))
            birth_date = row.get('birthday', None)
            if pd.isnull(birth_date):
                return np.nan
            birth_year = pd.to_datetime(birth_date, errors='coerce').year
            if pd.isnull(birth_year):
                return np.nan
            # åˆ¤æ–­å­¦æ ¡ç±»å‹
            if any(keyword in school for keyword in ['ä¸­å­¦', 'é«˜ä¸­', 'èŒæ•™', 'èŒé«˜', 'èŒå·¥', 'æŠ€æ ¡', 'ä¸€ä¸­', 'äºŒä¸­']):
                grad_age = 18
            elif any(keyword in school for keyword in ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡']):
                grad_age = 22
            else:
                grad_age = 20  # é»˜è®¤å€¼ï¼Œé€‚ç”¨äºæ— æ³•åˆ¤æ–­çš„æƒ…å†µ
            return birth_year + grad_age

        df['graduate_year'] = df.apply(infer_grad_year, axis=1)
        df['years_since_grad'] = 2025 - df['graduate_year']

    # æ•°å€¼å‹ç‰¹å¾å¤„ç†ï¼ˆMICEç®—æ³•ï¼‰
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    if numeric_cols:
        imputer = IterativeImputer(
            max_iter=10,
            random_state=42,
            initial_strategy='median'
        )
        df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

    # å…³é”®ç‰¹å¾éªŒè¯
    assert df['age'].isna().sum() == 0, "å¹´é¾„å­—æ®µä»å­˜åœ¨ç¼ºå¤±ï¼"
    assert df['label'].isna().sum() == 0, "æ ‡ç­¾å­—æ®µä»å­˜åœ¨ç¼ºå¤±ï¼"

    return df

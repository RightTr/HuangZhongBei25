import os
import pandas as pd
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import numpy as np
import re

def load_data(file_path):
    xl = pd.ExcelFile(file_path)

    for i in range(10):
        temp_df = xl.parse(sheet_name='æ•°æ®é›†', header=i)
        if 'b_aab022' in temp_df.columns:
            header_row = i
            break
    else:
        raise ValueError("Error")

    data = xl.parse(sheet_name='æ•°æ®é›†', header=header_row)
    print(data.columns.tolist())

    return data

def load_data_pre(file_path):
    xl = pd.ExcelFile(file_path)

    for i in range(10):
        temp_df = xl.parse(sheet_name='é¢„æµ‹é›†', header=i)
        if 'c_aac181' in temp_df.columns:
            header_row = i
            break
    else:
        raise ValueError("Error")

    data = xl.parse(sheet_name='é¢„æµ‹é›†', header=header_row)
    print(data.columns.tolist())

    return data

def advanced_missing_value_processing(df):
    # ç”Ÿæˆç¼ºå¤±åˆ†ææŠ¥å‘Šï¼ˆå»ºè®®ä¿ç•™æ­¤è¾“å‡ºç”¨äºéªŒè¯ï¼‰
    missing_analysis = df.isna().agg(['sum', 'mean']).T
    missing_analysis.columns = ['ç¼ºå¤±æ•°é‡', 'ç¼ºå¤±æ¯”ä¾‹']
    missing_analysis = missing_analysis.sort_values(by='ç¼ºå¤±æ¯”ä¾‹', ascending=False)
    print("ç¼ºå¤±å€¼åˆ†ææŠ¥å‘Šï¼š\n", missing_analysis.head(10))

    # åˆ é™¤é«˜ç¼ºå¤±ç‡ç‰¹å¾ï¼ˆé˜ˆå€¼è®¾ä¸º70%ï¼‰
    high_missing_cols = missing_analysis[missing_analysis['ç¼ºå¤±æ¯”ä¾‹'] > 0.7].index.tolist()
    if high_missing_cols:
        print(f"ğŸš® åˆ é™¤é«˜ç¼ºå¤±ç‡ç‰¹å¾ï¼š{high_missing_cols}")
        df = df.drop(columns=high_missing_cols)

    # æ¯•ä¸šå¹´ä»½æ¨ç®—ï¼ˆæ ¹æ®æ¯•ä¸šå­¦æ ¡ç±»å‹åˆ¤æ–­æ¯•ä¸šå¹´é¾„ï¼‰
    if 'graduate_school' in df.columns:
        def infer_grad_year(row):
            if pd.notnull(row.get('graduate_year')):
                return row['graduate_year']
            school = str(row.get('c_aac180', ''))
            birth_year = row.get('birth_year', None)
            if pd.isnull(birth_year):
                return np.nan
            # åˆ¤æ–­å­¦æ ¡ç±»å‹
            if any(keyword in school for keyword in ['ä¸­å­¦', 'é«˜ä¸­', 'èŒæ•™', 'èŒé«˜', 'èŒå·¥' ,'æŠ€æ ¡', 'ä¸€ä¸­', 'äºŒä¸­']):
                grad_age = 18
            elif any(keyword in school for keyword in ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡']):
                grad_age = 22
            else:
                grad_age = 20  # é»˜è®¤å€¼ï¼Œé€‚ç”¨äºæ— æ³•åˆ¤æ–­çš„æƒ…å†µ
            return birth_year + grad_age

        df['graduate_year'] = df.apply(infer_grad_year, axis=1)
        df['years_since_grad'] = 2025 - df['graduate_year']

    # åˆ†ç±»å‹ä¸æ•°å€¼å‹å·®å¼‚å¤„ç†
    # ç±»åˆ«å‹ç‰¹å¾å¤„ç†ï¼ˆæ·»åŠ 'Unknown'ç±»åˆ«ï¼‰
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    for col in categorical_cols:
        if col in df.columns:
            df[col] = df[col].astype('category').cat.add_categories(['Unknown']).fillna('Unknown')

    # æ•°å€¼å‹ç‰¹å¾å¤„ç†ï¼ˆMICEç®—æ³•ï¼‰
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    if numeric_cols:
        imputer = IterativeImputer(
            max_iter=10,
            random_state=42,
            initial_strategy='median'
        )
        df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

    # å…³é”®ç‰¹å¾éªŒè¯
    assert df['age'].isna().sum() == 0, "å¹´é¾„å­—æ®µä»å­˜åœ¨ç¼ºå¤±ï¼"

    return df

def extract_city_or_county(address):
    if "è¿œå®‰" in address:
        address = "è¿œå®‰"
    if "äº”å³°" in address:
        address = "äº”å³°"
    if "æ©æ–½" in address:
        address = "æ©æ–½"
    if "é•¿é˜³åœŸå®¶æ—è‡ªæ²»å¿" in address:
        address = "é•¿é˜³åœŸå®¶æ—è‡ªæ²»å¿"
    if "ç§­å½’" in address:
        address = "ç§­å½’"

    match = re.search(r"æ¹–åŒ—çœ\s*([^å¸‚\s]+å¸‚|[^å¿\s]+å¿)", address)
    if match:
        return match.group(1)
    match = re.search(r"([^å¸‚\s]+å¸‚|[^å¿\s]+å¿)", address)
    if match:
        return match.group(1)
    return address